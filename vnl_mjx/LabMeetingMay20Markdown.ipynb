{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization Framework for Muscle Parameters\n",
    "\n",
    "## Definitions\n",
    "\n",
    "Let:\n",
    "\n",
    "- *$\\theta$*: the parameters of the simulator (e.g., damping, force scaling)  \n",
    "- *$q(\\theta)$*: the variational distribution (e.g., $\\mathcal{N}(\\mu, \\sigma^2)$) over parameters — what we learn  \n",
    "- *$\\mathcal{D}$*: observed data — in this case, a target force distribution $p_{\\text{target}}(f)$  \n",
    "- *$p(f \\mid \\theta)$*: distribution of simulator outputs (e.g., muscle forces) given parameters $\\theta$  \n",
    "- *$p(\\theta)$*: prior distribution over parameters  \n",
    "- *$p(f)$*: marginal distribution of forces (not needed for optimization)\n",
    "\n",
    "---\n",
    "\n",
    "## Bayes' Rule\n",
    "\n",
    "We are interested in computing the **posterior** over muscle model parameters $\\theta$ given observed data $\\mathcal{D}$ — in this case, a target output force distribution:\n",
    "\n",
    "$$\n",
    "\\underbrace{p(\\theta \\mid \\mathcal{D})}_{\\text{Posterior}} = \n",
    "\\frac{\n",
    "\\underbrace{p(\\mathcal{D} \\mid \\theta)}_{\\text{Likelihood}} \\cdot \n",
    "\\underbrace{p(\\theta)}_{\\text{Prior}}\n",
    "}{\n",
    "\\underbrace{p(\\mathcal{D})}_{\\text{Evidence}}\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Definitions\n",
    "\n",
    "- **Posterior** ($p(\\theta \\mid \\mathcal{D})$):  \n",
    "  The probability distribution over parameters $\\theta$ *after* observing the data. This is what we want to infer.\n",
    "\n",
    "- **Likelihood** ($p(\\mathcal{D} \\mid \\theta)$):  \n",
    "  How likely the observed data $\\mathcal{D}$ would be if the simulator had parameters $\\theta$. In our context, how well the simulated force outputs match the target force distribution.\n",
    "\n",
    "- **Prior** ($p(\\theta)$):  \n",
    "  Our initial belief or uncertainty about the parameters *before* seeing the data. Often chosen to be uninformative (e.g., a standard Gaussian), or based on known physiology.\n",
    "\n",
    "- **Evidence** ($p(\\mathcal{D})$):  \n",
    "  The marginal probability of the data — often treated as a normalization constant. It ensures that the posterior is a valid probability distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### In Our Case:\n",
    "\n",
    "We define:\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = p_{\\text{target}}(f)\n",
    "$$\n",
    "\n",
    "This means: our observed data is a *target force distribution* — for instance, a Normal distribution centered at 0.2 N with some known variance, based on empirical muscle measurements.\n",
    "\n",
    "Then:\n",
    "\n",
    "- $p(\\mathcal{D} \\mid \\theta)$ means:  \n",
    "  *How likely is it that $\\theta$ would generate a simulated force distribution matching the observed one?*\n",
    "\n",
    "This term forms the core of the **distributional loss** we use during optimization (e.g., via KL divergence between simulated and target force distributions).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Optimization Objective via Variational Inference\n",
    "\n",
    "We approximate $p(\\theta \\mid \\mathcal{D})$ with a variational distribution $q(\\theta)$, and minimize the KL divergence:\n",
    "\n",
    "$$\n",
    "\\min_{q(\\theta)} \\; \\text{KL}(q(\\theta) \\, \\| \\, p(\\theta \\mid \\mathcal{D}))\n",
    "$$\n",
    "\n",
    "This is equivalent to minimizing the **Evidence Lower Bound (ELBO)**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{VI}} = \\mathbb{E}_{\\theta \\sim q(\\theta)} \\left[ -\\log p(\\mathcal{D} \\mid \\theta) \\right] + \\text{KL}(q(\\theta) \\, \\| \\, p(\\theta))\n",
    "$$\n",
    "\n",
    "> **Interpretation:** The ELBO quantifies how well a distribution over muscle parameters $q(\\theta)$ can explain the target force distribution $\\mathcal{D} = p_{\\text{target}}(f)$ while staying close to the prior $p(\\theta)$ — effectively scoring the probability that sampled parameters can plausibly generate the observed muscle behavior.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Expanding the Terms\n",
    "\n",
    "### 1. Likelihood Term (Distributional Loss)\n",
    "\n",
    "This measures how well a sampled $\\theta$ explains the observed force distribution.\n",
    "\n",
    "Assume:\n",
    "\n",
    "- $f_\\theta^{(1)}, \\dots, f_\\theta^{(T)}$: sampled forces from simulation  \n",
    "- Empirical output distribution:  \n",
    "  $$\n",
    "  p_\\theta(f) = \\mathcal{N}(\\mu_\\theta, \\sigma_\\theta^2)\n",
    "  $$\n",
    "- Target distribution:  \n",
    "  $$\n",
    "  p_{\\text{target}}(f) = \\mathcal{N}(\\mu_t, \\sigma_t^2)\n",
    "  $$\n",
    "\n",
    "Then the negative log-likelihood becomes:\n",
    "\n",
    "$$\n",
    "-\\log p(\\mathcal{D} \\mid \\theta) \\approx \\text{KL}(\\mathcal{N}(\\mu_\\theta, \\sigma_\\theta^2) \\, \\| \\, \\mathcal{N}(\\mu_t, \\sigma_t^2))\n",
    "$$\n",
    "\n",
    "So the **expected distributional loss** is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{likelihood}} = \\mathbb{E}_{\\theta \\sim q(\\theta)} \\left[ \\text{KL}(p_\\theta(f) \\, \\| \\, p_{\\text{target}}(f)) \\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Prior Term (Regularization)\n",
    "\n",
    "If:\n",
    "\n",
    "$$\n",
    "q(\\theta) = \\mathcal{N}(\\mu_q, \\sigma_q^2), \\quad p(\\theta) = \\mathcal{N}(\\mu_0, \\sigma_0^2)\n",
    "$$\n",
    "\n",
    "Then the KL divergence is analytic:\n",
    "\n",
    "$$\n",
    "\\text{KL}(q(\\theta) \\, \\| \\, p(\\theta)) =\n",
    "\\log \\left( \\frac{\\sigma_0}{\\sigma_q} \\right) +\n",
    "\\frac{\\sigma_q^2 + (\\mu_q - \\mu_0)^2}{2\\sigma_0^2} - \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Final Optimization Objective\n",
    "\n",
    "$$\n",
    "\\min_{\\mu_q, \\sigma_q} \\; \n",
    "\\underbrace{\n",
    "\\mathbb{E}_{\\theta \\sim q(\\theta)} \\left[ \\text{KL}(p_\\theta(f) \\, \\| \\, p_{\\text{target}}(f)) \\right]\n",
    "}_{\\text{distributional output loss}} \n",
    "+\n",
    "\\underbrace{\n",
    "\\text{KL}(q(\\theta) \\, \\| \\, p(\\theta))\n",
    "}_{\\text{parameter regularization}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## What This Means\n",
    "\n",
    "You're no longer trying to find the **single best** set of parameters $\\theta^*$.  \n",
    "Instead, you're finding a **distribution over parameters** $q(\\theta)$ such that:\n",
    "\n",
    "- Samples $\\theta \\sim q(\\theta)$ generate force distributions  \n",
    "- Those force distributions match your **target** biomechanics data on average\n",
    "\n",
    "The optimizer adjusts $\\mu_q$ and $\\sigma_q$ to minimize this mismatch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
