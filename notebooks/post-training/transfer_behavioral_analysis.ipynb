{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5727d4",
   "metadata": {},
   "source": [
    "# Behavioral Analysis of the Transfer Checkpoint\n",
    "\n",
    "This notebook will inspect the checkpoint trained from the swapped decoder from the track-mjx checkpoint for task driven down stream task. Specifically, I will make the following renderings to highlights the transfer performance.\n",
    "\n",
    "1. action through time\n",
    "2. intention clustering\n",
    "3. gait pattern graph for limbs\n",
    "4. force of the gait\n",
    "\n",
    "I will also do several rollout, with different bowl difficulties, potentially also with a flat arena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c115c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "# Send logging outputs to stdout (comment this out if preferred)\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "# plotting related\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from PIL import Image\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from track_mjx.agent import checkpointing\n",
    "from vnl_mjx.tasks.rodent import flat_arena, bowl_escape\n",
    "import mediapy as media\n",
    "from orbax import checkpoint as ocp\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "\n",
    "import jax\n",
    "# Enable persistent compilation cache.\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5defd8c",
   "metadata": {},
   "source": [
    "initialize your environment, also modify your env here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your checkpoint path\n",
    "# ckpt_path = \"/root/vast/scott-yang/vnl-mjx/model_checkpoints/250618_231352\"\n",
    "# flat center\n",
    "ckpt_path = \"/root/vast/scott-yang/vnl-mjx/model_checkpoints/250625_223902\"\n",
    "ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path)\n",
    "\n",
    "# Load config from checkpoint\n",
    "cfg = ckpt[\"cfg\"]\n",
    "# cfg[\"env_config\"][\"env_args\"][\"bowl_vsize\"] = 0.001\n",
    "env = bowl_escape.BowlEscape(config_overrides=cfg[\"env_config\"][\"env_args\"])\n",
    "jit_reset, jit_step = jax.jit(env.reset), jax.jit(env.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_fn = checkpointing.load_inference_fn(cfg, ckpt[\"policy\"])\n",
    "jit_inference_fn = jax.jit(inference_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3387002",
   "metadata": {},
   "source": [
    "some rendering helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some rendering related code\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def visualize_features(\n",
    "    features, window_size, title, frame, feature_mask: List[int] | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Render one frame of the sliding window plot.\n",
    "\n",
    "    For frame indices less than window_size, it displays the data from index 0 to current index,\n",
    "    but fixes the x-axis from 0 to window_size. For later frames, the most recent window_size time\n",
    "    steps are displayed. A red vertical line indicates the current time index.\n",
    "\n",
    "    Args:\n",
    "        features: A 2D numpy array of shape (feature_dim, time_dim) representing the features.\n",
    "        window_size: The size of the sliding window.\n",
    "        frame: The current frame index.\n",
    "\n",
    "    Returns:\n",
    "        rgb_array: A numpy array of shape (480, 640, 3) representing the rendered image.\n",
    "    \"\"\"\n",
    "    if type(features) is not np.ndarray:\n",
    "        features = np.array(features)\n",
    "    if feature_mask is not None:\n",
    "        features = features[feature_mask[0] : feature_mask[1], :]\n",
    "    # Compute global min and max to keep colormap consistent\n",
    "    global_vmin = float(features.min())\n",
    "    global_vmax = float(features.max())\n",
    "\n",
    "    current_idx = frame + 1  # current time step (1-indexed)\n",
    "\n",
    "    # Create the figure with fixed dimensions: 6.4x4.8 inches at dpi=100 gives 640x480 pixels.\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 4.8), dpi=100)\n",
    "    plt.tight_layout()\n",
    "    canvas = FigureCanvas(fig)\n",
    "\n",
    "    if current_idx < window_size:\n",
    "        # For early frames, plot data from 0 to current_idx.\n",
    "        window_data = features[:, :current_idx]  # shape: (147, current_idx)\n",
    "        # Set extent so the data covers [0, current_idx] in x,\n",
    "        # but later we force the x-axis to show 0 to window_size.\n",
    "        extent = [0, current_idx, 0, features.shape[0]]\n",
    "        ax.imshow(\n",
    "            window_data,\n",
    "            aspect=\"auto\",\n",
    "            interpolation=\"none\",\n",
    "            origin=\"lower\",\n",
    "            extent=extent,\n",
    "            vmin=global_vmin,\n",
    "            vmax=global_vmax,\n",
    "        )\n",
    "        # Fix x-axis to [0, window_size]\n",
    "        ax.set_xlim(0, window_size)\n",
    "        # Draw red vertical line at the current index\n",
    "        ax.axvline(x=current_idx, color=\"red\", linewidth=2)\n",
    "    else:\n",
    "        # For later frames, display the most recent window_size time steps.\n",
    "        window_data = features[\n",
    "            :, current_idx - window_size : current_idx\n",
    "        ]  # shape: (147, window_size)\n",
    "        extent = [current_idx - window_size, current_idx, 0, features.shape[0]]\n",
    "        ax.imshow(\n",
    "            window_data,\n",
    "            aspect=\"auto\",\n",
    "            interpolation=\"none\",\n",
    "            origin=\"lower\",\n",
    "            extent=extent,\n",
    "            vmin=global_vmin,\n",
    "            vmax=global_vmax,\n",
    "        )\n",
    "        # Even here, we fix the view from 0 to window_size (the window length).\n",
    "        ax.set_xlim(current_idx - window_size, current_idx)\n",
    "\n",
    "        ax.axvline(x=current_idx, color=\"red\", linewidth=2)\n",
    "    # ax.yaxis.set_visible(False)\n",
    "    # This hides the entire y-axis including ticks and labels\n",
    "    ax.set_title(title)\n",
    "    # Render the figure and convert to a NumPy RGB array using the proper canvas method.\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "    image = Image.frombytes(\"RGBA\", (width, height), s)\n",
    "    rgb_array = np.array(image.convert(\"RGB\"))\n",
    "    plt.close(fig)\n",
    "    return rgb_array\n",
    "\n",
    "\n",
    "##### PCA rendering related\n",
    "\n",
    "\n",
    "def plot_pca_intention(\n",
    "    idx,\n",
    "    episode_start,\n",
    "    pca_projections: np.ndarray,\n",
    "    feature_name: str,\n",
    "    pca: PCA,\n",
    "    n_components: int = 4,\n",
    "    terminated=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    plot pca intention progression of the episode\n",
    "    Args:\n",
    "        idx: the current timestep\n",
    "        episode_start: the start timestep of the episode\n",
    "        pca_projections: the pca projection of the episode, shape (timestep, n_components)\n",
    "        clip_idx: the clip index\n",
    "        feature_name: the feature name\n",
    "        n_components: the number of pca components to plot\n",
    "        ylim: the y-axis limit\n",
    "        terminated: whether the episode is terminated\n",
    "\n",
    "    \"\"\"\n",
    "    max_y = np.max(list(pca_projections[:, :n_components]))\n",
    "    min_y = np.min(list(pca_projections[:, :n_components]))\n",
    "    y_lim = (min_y - 0.2, max_y + 0.2)\n",
    "    window_size = 530\n",
    "    idx_in_this_episode = idx - episode_start  # the current timestep in this episode\n",
    "    plt.figure(figsize=(9.6, 4.8))\n",
    "    for pc_ind in range(n_components):\n",
    "        # Plot the PCA projection of the episode\n",
    "        plt.plot(\n",
    "            pca_projections[episode_start:idx, pc_ind],\n",
    "            label=f\"PC {pc_ind + 1} ({pca.explained_variance_ratio_[pc_ind]*100:.1f}%)\",\n",
    "        )\n",
    "        plt.scatter(idx - episode_start, pca_projections[idx - 1, pc_ind])\n",
    "    if terminated:\n",
    "        # Mark the episode termination\n",
    "        plt.axvline(x=idx - episode_start, color=\"r\", linestyle=\"-\")\n",
    "        plt.text(\n",
    "            idx - episode_start - 8,  # Adjust the x-offset as needed\n",
    "            sum(y_lim) / 2,  # Adjust the y-position as needed\n",
    "            \"Episode Terminated\",\n",
    "            color=\"r\",\n",
    "            rotation=90,\n",
    "        )  # Rotate the text vertically\n",
    "    if idx_in_this_episode <= window_size:\n",
    "        plt.xlim(0, window_size)\n",
    "    else:\n",
    "        plt.xlim(\n",
    "            idx_in_this_episode - window_size, idx_in_this_episode\n",
    "        )  # dynamically move xlim as time progress\n",
    "    sns.despine()\n",
    "    plt.ylim(*y_lim)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.title(f\"PCA {feature_name} Progression\")  # TODO make it configurabl\n",
    "    # Get the current figure\n",
    "    fig = plt.gcf()\n",
    "    # Create a canvas for rendering\n",
    "    canvas = FigureCanvas(fig)\n",
    "    # Render the canvas to a buffer\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "    # Convert the buffer to a PIL Image\n",
    "    image = Image.frombytes(\"RGBA\", (width, height), s)\n",
    "    rgb_array = np.array(image.convert(\"RGB\"))\n",
    "    return rgb_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/root/vast/scott-yang/vnl-mjx/model_checkpoints/250625_223902\"\n",
    "ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path)\n",
    "# once you compile the environment, you can easily swap the checkpoint\n",
    "# and do the rollout and renderings\n",
    "inference_fn = checkpointing.load_inference_fn(cfg, ckpt[\"policy\"])\n",
    "jit_inference_fn = jax.jit(inference_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1330478",
   "metadata": {},
   "source": [
    "### Generate a rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(2)\n",
    "\n",
    "rng, reset_rng = jax.random.split(rng)\n",
    "state = jit_reset(reset_rng)\n",
    "rollout = []\n",
    "network_info = []\n",
    "for i in tqdm(range(2000)):\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    ctrl, info = jit_inference_fn(state.obs, act_rng)\n",
    "    network_info.append(info)\n",
    "    state = jit_step(state, ctrl)\n",
    "    rollout.append(state)\n",
    "\n",
    "actions = np.array([r.data.ctrl for r in rollout]).T\n",
    "intentions = np.array([i[\"activations\"][\"intention\"] for i in network_info]).T\n",
    "actions.shape, intentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409bc0b",
   "metadata": {},
   "source": [
    "QC of the rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco\n",
    "\n",
    "render_every = 1\n",
    "fps = 1.0 / env.dt / render_every\n",
    "traj = rollout[::render_every]\n",
    "\n",
    "scene_option = mujoco.MjvOption()\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTFORCE] = False\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
    "\n",
    "frames = env.render(\n",
    "    traj,\n",
    "    camera=\"close_profile-rodent\",\n",
    "    scene_option=scene_option,\n",
    "    height=480,\n",
    "    width=640,\n",
    ")\n",
    "\n",
    "media.show_video(frames, fps=fps, loop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b6961",
   "metadata": {},
   "source": [
    "## Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b06711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "actions = np.array(actions)\n",
    "window_size = 300\n",
    "total_time = actions.shape[1]  # should be 499\n",
    "title = \"Actions\"\n",
    "# Use multiprocessing to parallelize the rendering.\n",
    "f = functools.partial(visualize_features, actions, window_size, title)\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    frames_plt_1 = pool.map(f, list(range(total_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco\n",
    "\n",
    "render_every = 1\n",
    "fps = 1.0 / env.dt / render_every\n",
    "traj = rollout[::render_every]\n",
    "\n",
    "scene_option = mujoco.MjvOption()\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTFORCE] = False\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
    "\n",
    "frames = env.render(\n",
    "    traj,\n",
    "    camera=\"close_profile-rodent\",\n",
    "    scene_option=scene_option,\n",
    "    height=480,\n",
    "    width=640,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0093480",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_videos = True\n",
    "# rendering the frames and save to disk\n",
    "combined_video = np.concatenate((frames, frames_plt_1), axis=2)\n",
    "media.show_video(combined_video, fps=fps, loop=False)\n",
    "if save_videos:\n",
    "    media.write_video(\n",
    "        f\"videos/flat_escape_action_plot.mp4\", combined_video, fps=fps, qp=18\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94543360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "intentions = np.array(intentions)\n",
    "window_size = 300\n",
    "total_time = intentions.shape[1]  # should be 499\n",
    "title = \"Intentions Vectors\"\n",
    "# Use multiprocessing to parallelize the rendering.\n",
    "f = functools.partial(visualize_features, intentions, window_size, title)\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    frames_plt_intention = pool.map(f, list(range(total_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3269fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_videos = True\n",
    "# rendering the frames and save to disk\n",
    "combined_video = np.concatenate((frames, frames_plt_intention), axis=2)\n",
    "media.show_video(combined_video, fps=fps, loop=False)\n",
    "if save_videos:\n",
    "    media.write_video(\n",
    "        f\"videos/flat_bowl_escape_intention_plot.mp4\", combined_video, fps=fps, qp=18\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(intentions.T)\n",
    "pca_embedded = pca.transform(intentions.T)\n",
    "pca_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained variance ratio\n",
    "pca.explained_variance_ratio_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "intentions = pca_embedded.T[:3, :]\n",
    "window_size = 300\n",
    "total_time = intentions.shape[1]  # should be 499\n",
    "title = \"Intentions Vectors\"\n",
    "# Use multiprocessing to parallelize the rendering.\n",
    "f = functools.partial(visualize_features, intentions, window_size, title)\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    frames_plt_intention = pool.map(f, list(range(total_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip the first frame, since we don't have intention for the first frame\n",
    "orig_backend = matplotlib.get_backend()\n",
    "matplotlib.use(\"Agg\")  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "worker = functools.partial(\n",
    "    plot_pca_intention,\n",
    "    episode_start=0,\n",
    "    pca=pca,\n",
    "    pca_projections=pca_embedded,\n",
    "    n_components=4,\n",
    "    feature_name=\"Intention\",\n",
    ")\n",
    "print(\"Rendering with PCA progression...\")\n",
    "# Use multiprocessing to parallelize the rendering of the reward graph\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    frames_pca = pool.map(worker, list(range(total_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_videos = True\n",
    "# rendering the frames and save to disk\n",
    "combined_video = np.concatenate((frames, frames_pca), axis=2)\n",
    "media.show_video(combined_video, fps=fps, loop=False)\n",
    "if save_videos:\n",
    "    media.write_video(\n",
    "        f\"videos/flat_bowl_escape_intention_plot.mp4\", combined_video, fps=fps, qp=18\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(actions.T)\n",
    "pca_embedded = pca.transform(actions.T)\n",
    "pca_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained variance ratio\n",
    "pca.explained_variance_ratio_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e010c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip the first frame, since we don't have intention for the first frame\n",
    "orig_backend = matplotlib.get_backend()\n",
    "matplotlib.use(\"Agg\")  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "worker = functools.partial(\n",
    "    plot_pca_intention,\n",
    "    episode_start=0,\n",
    "    pca=pca,\n",
    "    pca_projections=pca_embedded,\n",
    "    n_components=3,\n",
    "    feature_name=\"Action\",\n",
    ")\n",
    "print(\"Rendering with PCA progression...\")\n",
    "# Use multiprocessing to parallelize the rendering of the reward graph\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    frames_pca = pool.map(worker, list(range(total_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_videos = True\n",
    "# rendering the frames and save to disk\n",
    "combined_video = np.concatenate((frames, frames_pca), axis=2)\n",
    "media.show_video(combined_video, fps=fps, loop=False)\n",
    "if save_videos:\n",
    "    media.write_video(\n",
    "        f\"videos/flat_bowl_escape_action_pca_plot.mp4\", combined_video, fps=fps, qp=18\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f81231",
   "metadata": {},
   "source": [
    "# Gait Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rollout[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03da6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco\n",
    "from mujoco import mjx\n",
    "\n",
    "d = mujoco.MjData(env._mj_model)\n",
    "mjx_data = mujoco.mjx.put_data(env._mj_model, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49118245",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_geoms_id = np.unique(rollout[0].data.contact.geom2)\n",
    "collision_names = [\n",
    "    mujoco.mj_id2name(env._mj_model, mujoco.mjtObj.mjOBJ_GEOM, i)\n",
    "    for i in collision_geoms_id\n",
    "]\n",
    "collision_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"FL\", \"FR\", \"HL\", \"HR\"]\n",
    "\n",
    "\n",
    "mapping = {val: i // 4 for i, val in enumerate(collision_geoms_id)}\n",
    "\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mjx data into mj data, to be able to use mujoco python binding functions\n",
    "ds = [mjx.get_data(env._mj_model, r.data) for r in rollout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d02e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_barcode = []\n",
    "\n",
    "for d in ds:\n",
    "    code = np.zeros(4)\n",
    "    for i in d.contact.geom2:\n",
    "        code[mapping[i]] = 1\n",
    "    contacts_barcode.append(code)\n",
    "contacts_barcode = np.array(contacts_barcode).T\n",
    "contacts_barcode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89eef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def visualize_features(\n",
    "    features,\n",
    "    window_size,\n",
    "    title,\n",
    "    frame,\n",
    "    feature_mask: list[int] | None = None,\n",
    "    y_labels: list[str] | None = None,\n",
    "):\n",
    "    # ensure array\n",
    "    features = np.array(features)\n",
    "\n",
    "    # apply any row-mask (e.g. to select just 4 rows)\n",
    "    if feature_mask is not None:\n",
    "        features = features[feature_mask[0] : feature_mask[1], :]\n",
    "\n",
    "    # if the caller supplied y_labels, use them\n",
    "    if y_labels is None:\n",
    "        y_labels = [str(i) for i in range(features.shape[0])]\n",
    "\n",
    "    # fixed colormap limits for 0/1 one-hot\n",
    "    vmin, vmax = 0.0, 1.0\n",
    "\n",
    "    current_idx = frame + 1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 4.8), dpi=100)\n",
    "    plt.tight_layout()\n",
    "    canvas = FigureCanvas(fig)\n",
    "\n",
    "    # choose a black-and-white colormap: 'binary' is 0→white,1→black\n",
    "    cmap = \"binary\"\n",
    "\n",
    "    if current_idx < window_size:\n",
    "        window_data = features[:, :current_idx]\n",
    "        extent = [0, current_idx, 0, features.shape[0]]\n",
    "        ax.imshow(\n",
    "            window_data,\n",
    "            aspect=\"auto\",\n",
    "            interpolation=\"none\",\n",
    "            origin=\"lower\",\n",
    "            extent=extent,\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.set_xlim(0, window_size)\n",
    "        ax.axvline(x=current_idx, color=\"red\", linewidth=2)\n",
    "    else:\n",
    "        window_data = features[:, current_idx - window_size : current_idx]\n",
    "        extent = [current_idx - window_size, current_idx, 0, features.shape[0]]\n",
    "        ax.imshow(\n",
    "            window_data,\n",
    "            aspect=\"auto\",\n",
    "            interpolation=\"none\",\n",
    "            origin=\"lower\",\n",
    "            extent=extent,\n",
    "            cmap=cmap,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.set_xlim(current_idx - window_size, current_idx)\n",
    "        ax.axvline(x=current_idx, color=\"red\", linewidth=2)\n",
    "\n",
    "    # place y-ticks at the *center* of each row\n",
    "    n_feats = features.shape[0]\n",
    "    centers = np.arange(n_feats) + 0.5\n",
    "    ax.set_yticks(centers)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # render to RGB array\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "    image = Image.frombytes(\"RGBA\", (width, height), s)\n",
    "    rgb_array = np.array(image.convert(\"RGB\"))\n",
    "    plt.close(fig)\n",
    "    return rgb_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bbab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "window_size = 300\n",
    "total_time = contacts_barcode.shape[1]  # should be 499\n",
    "title = \"Gait Contact Patterns\"\n",
    "# Use multiprocessing to parallelize the rendering.\n",
    "f = functools.partial(\n",
    "    visualize_features, contacts_barcode, window_size, title, y_labels=labels\n",
    ")\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    frames_plt_barcode = pool.map(f, list(range(total_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rendering the frames and save to disk\n",
    "save_videos = True\n",
    "combined_video = np.concatenate((frames, frames_plt_barcode), axis=2)\n",
    "media.show_video(combined_video, fps=fps, loop=False)\n",
    "if save_videos:\n",
    "    media.write_video(\n",
    "        f\"videos/hilly_escape_new_checkpoint_better_init_disk_gait_contact_patterns.mp4\",\n",
    "        combined_video,\n",
    "        fps=fps,\n",
    "        qp=18,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d4bf6",
   "metadata": {},
   "source": [
    "Get the force using the touch sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae10c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "touches = np.array([env._get_touch_sensors(r.data) for r in rollout]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75404b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "labels = [\"HL\", \"HR\", \"FL\", \"FR\"]\n",
    "window_size = 300\n",
    "total_time = touches.shape[1]  # should be 499\n",
    "title = \"Touch Sensors\"\n",
    "# Use multiprocessing to parallelize the rendering.\n",
    "f = functools.partial(visualize_features, touches, window_size, title, y_labels=labels)\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    frames_plt_touch = pool.map(f, list(range(total_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120501ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_videos = True\n",
    "# rendering the frames and save to disk\n",
    "combined_video = np.concatenate((frames, frames_plt_touch), axis=2)\n",
    "media.show_video(combined_video, fps=fps, loop=False)\n",
    "if save_videos:\n",
    "    media.write_video(\n",
    "        f\"videos/flat_bowl_escape_touch_gait_pattern.mp4\",\n",
    "        combined_video,\n",
    "        fps=fps,\n",
    "        qp=18,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0255c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track-mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
